{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afebad71082b978",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbbfa68a2c2ad9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:50.980067Z",
     "start_time": "2024-06-01T10:03:47.872037Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from datasets import SurfaceDatasetXGB\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fft import fft, fftfreq\n",
    "# from datetime import datetime\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ea75087b5a6c3",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6abec83e5778172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.012980Z",
     "start_time": "2024-06-01T10:03:50.981065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d566fb3a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b62f1e105bcc84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b5555a4fa10241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.027939Z",
     "start_time": "2024-06-01T10:03:51.018964Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./Documents/Project_surface_classification/dataset_new/dataset') # TO DO\n",
    "HISTORY_DIR = Path('./Documents/Project_surface_classification/results') # TO DO\n",
    "LOOKBACK = 8/3\n",
    "SAMPLING_FREQUENCY = 75.\n",
    "DATASET_FREQUENCY = 150.\n",
    "SUBSET = ('imu',)\n",
    "CONFIGURATIONS = ('6W',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529717ff2812af0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b514e991-6e56-4096-adfd-595ffd5de384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nwjan\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503fce34bed6d813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.074815Z",
     "start_time": "2024-06-01T10:03:51.031929Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open('./Documents/Project_surface_classification/labels.json') as fp: # TO DO\n",
    "    labels = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bb38f00e195362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.090771Z",
     "start_time": "2024-06-01T10:03:51.076809Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = [(DATA_DIR.joinpath(key + '.csv'), values['surface']) for key, values in labels.items() if values['kinematics'] in CONFIGURATIONS and values['spacing'] == 'R1' and 'T1' in values['trajectory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac562fc5c93cd196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.105733Z",
     "start_time": "2024-06-01T10:03:51.093764Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.Series([run[0] for run in dataset], name='bag_name')\n",
    "y_primary = [run[1] for run in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce103ccb3fe0581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.120692Z",
     "start_time": "2024-06-01T10:03:51.107726Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# y_secondary = []\n",
    "# y_secondary = ['slippery' if label in ('1_Panele', '5_Spienione_PCV', '6_Linoleum')\n",
    "#                else 'grippy' if label in ('3_Wykladzina_jasna', '8_Pusta_plyta', '9_podklady')\n",
    "#                else 'neutral' for label in y_primary]\n",
    "y_secondary = ['slippery' if label in ('3_Wykladzina_jasna', '4_Trawa')\n",
    "               else 'grippy' if label in ('5_Spienione_PCV', '8_Pusta_plyta', '9_podklady', '10_Mata_ukladana')\n",
    "               else 'neutral' for label in y_primary] # Pawel set\n",
    "# y_secondary = ['slippery' if label in ('3_Wykladzina_jasna', '4_Trawa')\n",
    "#                else 'grippy' if label in ('2_Wykladzina_czarna', '5_Spienione_PCV', '9_podklady', '10_Mata_ukladana')\n",
    "#                else 'neutral' for label in y_primary] # Clustering set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28cd1c677f86f806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:03:51.385045Z",
     "start_time": "2024-06-01T10:03:51.371084Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit(y_primary)\n",
    "classes = lb.classes_\n",
    "num_classes = len(classes)\n",
    "y = lb.transform(y_primary)\n",
    "# y = y.reshape(-1, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59200394bfc51d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f462da904175a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:04:06.898766Z",
     "start_time": "2024-06-01T10:03:52.435712Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_data = SurfaceDatasetXGB(X, y, sample_freq=SAMPLING_FREQUENCY, data_freq=DATASET_FREQUENCY, lookback=LOOKBACK, subset=SUBSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ec41b0-28f8-4e6d-b004-673d0b897ad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:00:51.148395Z",
     "start_time": "2024-06-01T10:00:51.139418Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'reg_alpha': [0.1, 0.5],\n",
    "    'reg_lambda': [0.1, 0.5],\n",
    "    'scale_pos_weight': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467a8774a8740fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9acb973ef0d7300b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T08:35:45.078541Z",
     "start_time": "2024-05-13T08:01:19.597614Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "\n",
    "sss = StratifiedShuffleSplit(test_size=0.2)\n",
    "for i, (training_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    \n",
    "    # Initialize the model in each split\n",
    "    multi_softmax = XGBClassifier(objective = 'multi:softprob',\n",
    "                                  num_class=num_classes,\n",
    "                                  eval_metric=['merror','mlogloss'])\n",
    "    \n",
    "    train_subset = Subset(cv_data, training_index)\n",
    "    test_subset = Subset(cv_data, test_index)\n",
    "\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=len(train_subset))\n",
    "    test_dataloader = DataLoader(test_subset, batch_size=len(test_subset))\n",
    "\n",
    "    X_train, y_train = next(iter(train_dataloader))\n",
    "    X_test, y_true = next(iter(test_dataloader))\n",
    "    \n",
    "    clf_search = RandomizedSearchCV(estimator=multi_softmax, \n",
    "                                     param_distributions=param_grid, \n",
    "                                     cv=5, scoring='accuracy', n_jobs=-1, verbose=10)\n",
    "\n",
    "    clf_search.fit(X_train, y_train)\n",
    "    # y_pred = clf_search.predict(X_test)\n",
    "\n",
    "    xgb = XGBClassifier(objective = 'multi:softprob',\n",
    "                        params = clf_search.best_params_,\n",
    "                        num_class=num_classes,\n",
    "                        eval_metric=['merror','mlogloss'])\n",
    "\n",
    "    importances = clf_search.best_estimator_.feature_importances_\n",
    "    idx = np.argsort(importances) # indexes with the highest importance \n",
    "    best_features = idx[-25:] # 25 best features\n",
    "    xgb.fit(X_train[:, best_features], y_train)\n",
    "    y_pred = xgb.predict(X_test[:, best_features])\n",
    "    \n",
    "    history[i + 1] = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='macro'),\n",
    "        'best_features': cv_data.engineered_features[best_features[::-1]],\n",
    "    }\n",
    "\n",
    "history_filename = 'XGB_' + '_'.join(CONFIGURATIONS + SUBSET) + '_' + time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "json.dump(history, open(HISTORY_DIR / f'{history_filename}.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48aca0-1afe-4eed-8ea3-fe794893fddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
