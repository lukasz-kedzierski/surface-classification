{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T21:47:03.048843Z",
     "start_time": "2024-03-11T21:47:03.002672Z"
    }
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "main_dir = Path('../data/fixed/')\n",
    "target_dir = Path('../data/dataset/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T21:47:03.997820Z",
     "start_time": "2024-03-11T21:47:03.985852Z"
    }
   },
   "id": "8e7ffca97cee5487",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 75\u001B[0m\n\u001B[0;32m     73\u001B[0m columns_left \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPower_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(data[\u001B[38;5;241m0\u001B[39m])) \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     74\u001B[0m columns_right \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPower_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(data[\u001B[38;5;241m0\u001B[39m])) \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 75\u001B[0m power \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mabs\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1e3\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdictionary\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     76\u001B[0m power_left \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([[\u001B[38;5;28mabs\u001B[39m(\u001B[38;5;28mtuple\u001B[39m(dictionary\u001B[38;5;241m.\u001B[39mvalues())[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mtuple\u001B[39m(dictionary\u001B[38;5;241m.\u001B[39mvalues())[\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, dictionary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(line) \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m data], columns\u001B[38;5;241m=\u001B[39mcolumns_left)\n\u001B[0;32m     77\u001B[0m power_right \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([[\u001B[38;5;28mabs\u001B[39m(\u001B[38;5;28mtuple\u001B[39m(dictionary\u001B[38;5;241m.\u001B[39mvalues())[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mtuple\u001B[39m(dictionary\u001B[38;5;241m.\u001B[39mvalues())[\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, dictionary \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(line) \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m data], columns\u001B[38;5;241m=\u001B[39mcolumns_right)\n",
      "File \u001B[1;32mD:\\GitHub Projects\\Surface classification\\surface-classification\\venv\\lib\\site-packages\\pandas\\core\\frame.py:840\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    839\u001B[0m         columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[1;32m--> 840\u001B[0m     arrays, columns, index \u001B[38;5;241m=\u001B[39m \u001B[43mnested_data_to_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[0;32m    842\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[0;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    848\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[0;32m    849\u001B[0m         arrays,\n\u001B[0;32m    850\u001B[0m         columns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    853\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    854\u001B[0m     )\n\u001B[0;32m    855\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\GitHub Projects\\Surface classification\\surface-classification\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[1;34m(data, columns, index, dtype)\u001B[0m\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_named_tuple(data[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    518\u001B[0m     columns \u001B[38;5;241m=\u001B[39m ensure_index(data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fields)\n\u001B[1;32m--> 520\u001B[0m arrays, columns \u001B[38;5;241m=\u001B[39m \u001B[43mto_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    521\u001B[0m columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\GitHub Projects\\Surface classification\\surface-classification\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:835\u001B[0m, in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, dtype)\u001B[0m\n\u001B[0;32m    832\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arrays, columns\n\u001B[0;32m    834\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m--> 835\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43m_list_to_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data[\u001B[38;5;241m0\u001B[39m], abc\u001B[38;5;241m.\u001B[39mMapping):\n\u001B[0;32m    837\u001B[0m     arr, columns \u001B[38;5;241m=\u001B[39m _list_of_dict_to_arrays(data, columns)\n",
      "File \u001B[1;32mD:\\GitHub Projects\\Surface classification\\surface-classification\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:856\u001B[0m, in \u001B[0;36m_list_to_arrays\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    853\u001B[0m     content \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mto_object_array_tuples(data)\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;66;03m# list of lists\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m     content \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_object_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# get all subfolders containing bags\n",
    "bag_paths = [folder for folder in main_dir.rglob('**/') if any(subfolder in folder.__str__() for subfolder in ('T1\\\\', 'T2\\\\'))]\n",
    "labels = {}\n",
    "\n",
    "for bag_path in bag_paths:\n",
    "    # split path into chunks\n",
    "    subfolders = os.path.normpath(bag_path).split(os.sep)\n",
    "    key = subfolders[-1]\n",
    "    \n",
    "    # get cmd_vel, imu_data, odom, and servo_data\n",
    "    bag_files = [bag_path.joinpath(bag_file) for bag_file in os.listdir(bag_path) if bag_file in ('cmd_vel.csv', 'imu-data.csv', 'odom.csv', 'Servo_data.csv')]\n",
    "\n",
    "    # read and merge tables\n",
    "    dataframes = [pd.read_csv(bag_file) for bag_file in bag_files]\n",
    "    dataframe = ft.reduce(lambda left, right: pd.merge(left, right, how='outer', on='Time'), dataframes)\n",
    "\n",
    "    # clean resulting dataframe\n",
    "    dataframe = dataframe[dataframe.columns.drop(list(dataframe.filter(regex='header')))]\n",
    "    dataframe.columns = ['Time', 'linear.x', 'linear.y', 'linear.z', 'angular.x', 'angular.y', 'angular.z',\n",
    "                         'orientation.x', 'orientation.y', 'orientation.z',\n",
    "                         'orientation.w', 'orientation_covariance_0', 'orientation_covariance_1',\n",
    "                         'orientation_covariance_2', 'orientation_covariance_3',\n",
    "                         'orientation_covariance_4', 'orientation_covariance_5',\n",
    "                         'orientation_covariance_6', 'orientation_covariance_7',\n",
    "                         'orientation_covariance_8', 'angular_velocity.x', 'angular_velocity.y',\n",
    "                         'angular_velocity.z', 'angular_velocity_covariance_0',\n",
    "                         'angular_velocity_covariance_1', 'angular_velocity_covariance_2',\n",
    "                         'angular_velocity_covariance_3', 'angular_velocity_covariance_4',\n",
    "                         'angular_velocity_covariance_5', 'angular_velocity_covariance_6',\n",
    "                         'angular_velocity_covariance_7', 'angular_velocity_covariance_8',\n",
    "                         'linear_acceleration.x', 'linear_acceleration.y',\n",
    "                         'linear_acceleration.z', 'linear_acceleration_covariance_0',\n",
    "                         'linear_acceleration_covariance_1', 'linear_acceleration_covariance_2',\n",
    "                         'linear_acceleration_covariance_3', 'linear_acceleration_covariance_4',\n",
    "                         'linear_acceleration_covariance_5', 'linear_acceleration_covariance_6',\n",
    "                         'linear_acceleration_covariance_7', 'linear_acceleration_covariance_8',\n",
    "                         'child_frame_id', 'pose.pose.position.x',\n",
    "                         'pose.pose.position.y', 'pose.pose.position.z',\n",
    "                         'pose.pose.orientation.x', 'pose.pose.orientation.y',\n",
    "                         'pose.pose.orientation.z', 'pose.pose.orientation.w', 'pose.covariance',\n",
    "                         'twist.twist.linear.x', 'twist.twist.linear.y', 'twist.twist.linear.z',\n",
    "                         'twist.twist.angular.x', 'twist.twist.angular.y',\n",
    "                         'twist.twist.angular.z', 'twist.covariance',\n",
    "                         'values']\n",
    "    dataframe = dataframe[['Time',\n",
    "                           'linear.x', 'angular.z', # cmd_vel\n",
    "                           'linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z', 'angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z', # imu\n",
    "                           'pose.pose.position.x', 'pose.pose.position.y', 'twist.twist.linear.x', 'twist.twist.angular.z', # odom\n",
    "                           'values']] # servo\n",
    "\n",
    "    # trim first and last rows for more coherent data\n",
    "    clip_var = int(len(dataframe) * .1)\n",
    "    dataframe = dataframe.iloc[clip_var:-clip_var].reset_index(drop=True)\n",
    "\n",
    "    # fill missing values\n",
    "    dataframe.ffill(inplace=True)\n",
    "    dataframe.bfill(inplace=True)\n",
    "\n",
    "    # set initial timestep at 0\n",
    "    dataframe['Time'] -= dataframe['Time'].min()\n",
    "\n",
    "    # remove gravity from acceleration wrt z axis\n",
    "    dataframe['linear_acceleration.z'] -= dataframe['linear_acceleration.z'].mean()\n",
    "    \n",
    "    # get power values scaled down by 1e3 factor\n",
    "    data = dataframe['values'].tolist()\n",
    "    data = [line.replace(', ', '];[') for line in data]\n",
    "    data = [line.replace('[', '') for line in data]\n",
    "    data = [line.replace(']', '') for line in data]\n",
    "    data = [line.split(sep=';') for line in data]\n",
    "    data = [[yaml.safe_load(line) for line in separate_lines] for separate_lines in data]\n",
    "    columns = ['Power_' + str(idx + 1) for idx in range(len(data[0]))]\n",
    "    columns_left = ['Power_' + str(idx + 1) for idx in range(len(data[0])) if idx % 2 == 0]\n",
    "    columns_right = ['Power_' + str(idx + 1) for idx in range(len(data[0])) if idx % 2 != 0]\n",
    "    power = pd.DataFrame([[abs(tuple(dictionary.values())[1] * tuple(dictionary.values())[2]) / 1e3 for dictionary in line] for line in data], columns=columns)\n",
    "    power_left = pd.DataFrame([[abs(tuple(dictionary.values())[1] * tuple(dictionary.values())[2]) / 1e3 for idx, dictionary in enumerate(line) if idx % 2 == 0] for line in data], columns=columns_left)\n",
    "    power_right = pd.DataFrame([[abs(tuple(dictionary.values())[1] * tuple(dictionary.values())[2]) / 1e3 for idx, dictionary in enumerate(line) if idx % 2 != 0] for line in data], columns=columns_right)\n",
    "    dataframe = pd.concat([dataframe, power], axis=1)\n",
    "    dataframe['mean_power'] = power.mean(axis=1)\n",
    "    dataframe['mean_power_left'] = power_left.mean(axis=1)\n",
    "    dataframe['mean_power_right'] = power_right.mean(axis=1)\n",
    "    dataframe.drop(columns=['values'], inplace=True)\n",
    "\n",
    "    # write dataframe to csv\n",
    "    dataframe.to_csv(target_dir.joinpath(key + '.csv'))\n",
    "    \n",
    "    # gather labels\n",
    "    sample_dict = {'surface': subfolders[3], 'kinematics': subfolders[4], 'spacing': subfolders[5], 'trajectory': subfolders[6]}\n",
    "    labels[key] = sample_dict\n",
    "\n",
    "# dump labels to json\n",
    "with open('../data/labels.json', 'w') as fp:\n",
    "    json.dump(labels, fp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T21:47:59.281837Z",
     "start_time": "2024-03-11T21:47:05.296298Z"
    }
   },
   "id": "e3cab1f50ed47354",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a5c82f86341df41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
